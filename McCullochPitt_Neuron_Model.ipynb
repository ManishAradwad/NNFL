{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "McCullochPitt_Neuron_Model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMJSFyTyiQKopgYBIP9e14t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManishAradwad/NNFL/blob/master/McCullochPitt_Neuron_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iSTrOTtxYVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" Implementation of different logic gates using McCulloch-Pitt's/Perceptron model of Neuron. \"\"\"\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjypRsz70-bh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "69745ad0-f5a4-4cf1-daae-2f50cef14268"
      },
      "source": [
        "class Perceptron():\n",
        "  def __init__(self,input_size=2,epochs=10):\n",
        "    self.W = np.ones(input_size+1) # +1 for bias\n",
        "    self.epochs = epochs\n",
        "\n",
        "  def activation_fn(self,x):\n",
        "    return 1 if x>=1 else 0\n",
        "\n",
        "  def predict(self,x):\n",
        "    z = self.W.T.dot(x)\n",
        "    y = self.activation_fn(z)\n",
        "    return y\n",
        "\n",
        "  def adjust_wts(self,X,o):\n",
        "    for _ in range(self.epochs):\n",
        "      for i in range(X.shape[0]):\n",
        "        x = np.insert(X[i],0,1)\n",
        "        y = self.predict(x)\n",
        "        error = o[i] - y\n",
        "        self.W = self.W + error * x\n",
        "\n",
        "  def final_op(self,X):\n",
        "    print(self.W)\n",
        "    outputs = []\n",
        "    for i in range(X.shape[0]):\n",
        "      x = np.insert(X[i],0,1)\n",
        "      outputs.append(self.W.T.dot(x))\n",
        "    return outputs\n",
        "\n",
        "input_array = np.array([[0,0,0],\n",
        "                        [0,0,1],\n",
        "                        [0,1,0],\n",
        "                        [0,1,1],\n",
        "                        [1,0,0],\n",
        "                        [1,0,1],\n",
        "                        [1,1,0],\n",
        "                        [1,1,1],])\n",
        "and_output = np.array([0,1,1,1,1,1,1,1])\n",
        "\n",
        "# input_array = np.array([[0,0],\n",
        "#                         [0,1],\n",
        "#                         [1,0],\n",
        "#                         [1,1],])\n",
        "\n",
        "# and_output = np.array([0,1,1,1])\n",
        "\n",
        "perc = Perceptron(input_size=3)\n",
        "perc.adjust_wts(input_array,and_output)\n",
        "result = map(perc.activation_fn,perc.final_op(input_array))\n",
        "print(list(result))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 1. 1.]\n",
            "[0, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}